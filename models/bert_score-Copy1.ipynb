{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import BERTScorer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from lsh import LSH\n",
    "from fast_lexrank import Lexrank\n",
    "import time, emoji, string\n",
    "from joblib import Parallel, delayed\n",
    "# hide the loading messages\n",
    "import re\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Id                                              Tweet\n",
      "0  824941360449015808  RT @MENTION : Emergency Rally Against Trump's ...\n",
      "1  824941519857610752  RT @MENTION : Theresa May has not apologized t...\n",
      "2  824941616314122240  RT @MENTION : Trump's Immigration Ban Excludes...\n",
      "3  824942056741167105  RT @MENTION : Trump's immigration order expand...\n",
      "4  824942966875774976  ALERT : Senator John McCain Threatens Action O...\n",
      "(123385, 2)\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data = pd.read_csv('/home/ehoang/hnt/data/processed_travel_ban.csv')\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rt, @USER, @URL, emoji\n",
    "data['Tweet'] = data['Tweet'].apply(lambda x: x.replace('@MENTION', \"\").replace(\"@URL\", \"\").\n",
    "                                    replace(\"@EMAIL\", \"\").lower())\n",
    "data['Tweet'] = data['Tweet'].apply(lambda x: re.sub(\"^ ?(rt ?)+\", \"\", x))                              \n",
    "data['Tweet'] = data['Tweet'].apply(lambda x: re.sub('^( ?: ?)', '', x))\n",
    "data['Tweet'] = data['Tweet'].apply(lambda x: re.sub(\"  +\", \" \", x))\n",
    "data['Tweet'] = data['Tweet'].apply(lambda x: ''.join(c for c in x if c not in emoji.UNICODE_EMOJI).strip())\n",
    "# remove stopwords, punctuation\n",
    "stopWords = stopwords.words('english')\n",
    "data['Tweet1'] = data['Tweet'].apply(lambda x: ' '.join(y for y in x.split(\" \") if y not in stopWords))\n",
    "data['Tweet1'] = data['Tweet1'].apply(lambda x: x.translate(str.maketrans('', '',  string.punctuation)))\n",
    "data['Tweet1'] = data['Tweet1'].apply(lambda x: re.sub('“|…|’|‘|”|—|→', \"\", x))\n",
    "data['Tweet1'] = data['Tweet1'].apply(lambda x: re.sub(' +', ' ',x).strip())\n",
    "\n",
    "# remove tweets #unique words less than haft of length\n",
    "data['uniWPercent'] = data['Tweet1'].apply(lambda x: 0 if len(set(x.split(\" \")))/len(x.split(\" \")) <= 0.5 else len(x.split(\" \")))\n",
    "data = data[data['uniWPercent']!=0]\n",
    "# # remove tweets with lengths < 3, duplicates\n",
    "while data['uniWPercent'].min() <=2:\n",
    "    data = data[data['uniWPercent'] >2]\n",
    "    data['uniWPercent'] = data['Tweet1'].apply(lambda x: 0 if len(set(x.split(\" \")))/len(x.split(\" \")) <= 0.5 else len(x.split(\" \")))\n",
    "# # # remove duplicates\n",
    "data.drop_duplicates(subset=['Tweet1'], keep='first', inplace = True)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remained_index = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3313)\n"
     ]
    }
   ],
   "source": [
    "#extract tfidf vector\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidfData = tfidf.fit_transform(data['Tweet1'])\n",
    "print(tfidfData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "lsh_tfidf = LSH(tfidfData)\n",
    "lsh_tfidf.train(num_bits = 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = lsh_tfidf.extract_nearby_bins(max_search_radius = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "8\n",
      "4\n",
      "4\n",
      "8\n",
      "10\n",
      "6\n",
      "9\n",
      "3\n",
      "4\n",
      "7\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "10\n",
      "5\n",
      "9\n",
      "6\n",
      "7\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "5\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "2\n",
      "2\n",
      "7\n",
      "7\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "8\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "7\n",
      "4\n",
      "2\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "2\n",
      "8\n",
      "7\n",
      "5\n",
      "5\n",
      "4\n",
      "9\n",
      "4\n",
      "6\n",
      "3\n",
      "11\n",
      "5\n",
      "5\n",
      "9\n",
      "8\n",
      "5\n",
      "5\n",
      "6\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "9\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "6\n",
      "2\n",
      "4\n",
      "3\n",
      "8\n",
      "5\n",
      "4\n",
      "3\n",
      "9\n",
      "2\n",
      "4\n",
      "4\n",
      "6\n",
      "2\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "10\n",
      "3\n",
      "6\n",
      "4\n",
      "8\n",
      "5\n",
      "7\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "9\n",
      "3\n",
      "2\n",
      "6\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "5\n",
      "6\n",
      "4\n",
      "6\n",
      "3\n",
      "4\n",
      "7\n",
      "4\n",
      "5\n",
      "4\n",
      "2\n",
      "3\n",
      "6\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "7\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "2\n",
      "2\n",
      "5\n",
      "6\n",
      "4\n",
      "2\n",
      "8\n",
      "5\n",
      "2\n",
      "6\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "7\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "7\n",
      "4\n",
      "5\n",
      "6\n",
      "9\n",
      "9\n",
      "3\n",
      "2\n",
      "9\n",
      "3\n",
      "4\n",
      "6\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for b in buckets:\n",
    "    print(len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3f7741381088>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "data = np.array(data['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ehoang/miniconda3/envs/py37/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1324: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus-level BLEU: 0.958\n",
      "Sentence-level BLEU: [0.962, 0.954]\n",
      "Group BLEU: {'Test Group 2': 0.962, 'Test Group 1': 0.962}\n"
     ]
    }
   ],
   "source": [
    "from vizseq.scorers.bert_score import BERTScoreScorer\n",
    "scorer = BERTScoreScorer(corpus_level=True, sent_level=True, n_workers=4)\n",
    "ref = [['This is a sample #1 reference.', 'This is a sample #2 reference.']]\n",
    "hypo = ['This is a sample #1 prediction.', 'This is a sample #2 model prediction.']\n",
    "tags = [['Test Group 1', 'Test Group 2']]\n",
    "scores = scorer.score(hypo, ref, tags=tags)\n",
    "print(f'Corpus-level BLEU: {scores.corpus_score}')\n",
    "print(f'Sentence-level BLEU: {scores.sent_scores}')\n",
    "print(f'Group BLEU: {scores.group_scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scorers = []\n",
    "# for i in range(2):\n",
    "#     scorers.append(BERTScorer(lang='en', rescale_with_baseline = True, idf = True, \n",
    "#                               idf_sents = list(data['Tweet']), device = 'cuda:'+str(i)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.372214794158936\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time_start = time.time()\n",
    "scorer = BERTScorer(lang='en', rescale_with_baseline = True, idf = False, device = 'cpu', nthreads = 1)\n",
    "print(time.time() - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.90235567092896\n"
     ]
    }
   ],
   "source": [
    "# time_start = time.time()\n",
    "# scorers = []\n",
    "# for i in range(2):\n",
    "#     scorer = BERTScorer(lang='en', rescale_with_baseline = True, idf = False, device = 'cpu')\n",
    "#     scorers.append(scorer)\n",
    "# print(time.time()-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScorer(hash=roberta-large_L17_no-idf_version=0.3.6(hug_trans=3.3.1)-rescaled, batch_size=64, nthreads=4)\n",
      "BERTScorer(hash=roberta-large_L17_no-idf_version=0.3.6(hug_trans=3.3.1)-rescaled, batch_size=64, nthreads=4)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(scorers)):\n",
    "    print(scorers[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.6714]), tensor([0.4557]), tensor([0.5621]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorers[1].score(['thi huyen'], ['thi huyen nguyen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#buckets: 220\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/site-packages/joblib/externals/loky/backend/queues.py\", line 150, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/site-packages/joblib/externals/loky/backend/reduction.py\", line 243, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/site-packages/joblib/externals/loky/backend/reduction.py\", line 236, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/site-packages/joblib/externals/cloudpickle/cloudpickle.py\", line 267, in dump\n    return Pickler.dump(self, obj)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 437, in dump\n    self.save(obj)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 887, in _batch_setitems\n    save(v)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 816, in save_list\n    self._batch_appends(obj)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 843, in _batch_appends\n    save(tmp[0])\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 771, in save_tuple\n    save(element)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 786, in save_tuple\n    save(element)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 524, in save\n    rv = reduce(self.proto)\nTypeError: can't pickle _regex.Pattern objects\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3ec141647187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#buckets: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuckets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_bert_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbIdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbIdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuckets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m# _ = Parallel(n_jobs=2)(delayed(compute_bert_score)(0.2, bIdx, b, scorer) for bIdx, [b, scorer] in enumerate(zip(buckets[0:2], scorers)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Could not pickle the task to send it to the workers."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/site-packages/joblib/externals/loky/backend/queues.py\", line 150, in _feed\n",
      "    obj_ = dumps(obj, reducers=reducers)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/site-packages/joblib/externals/loky/backend/reduction.py\", line 243, in dumps\n",
      "    dump(obj, buf, reducers=reducers, protocol=protocol)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/site-packages/joblib/externals/loky/backend/reduction.py\", line 236, in dump\n",
      "    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/site-packages/joblib/externals/cloudpickle/cloudpickle.py\", line 267, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 437, in dump\n",
      "    self.save(obj)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 887, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 816, in save_list\n",
      "    self._batch_appends(obj)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 843, in _batch_appends\n",
      "    save(tmp[0])\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 771, in save_tuple\n",
      "    save(element)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 786, in save_tuple\n",
      "    save(element)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/pickle.py\", line 524, in save\n",
      "    rv = reduce(self.proto)\n",
      "TypeError: can't pickle _regex.Pattern objects\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/site-packages/joblib/externals/loky/backend/queues.py\", line 175, in _feed\n",
      "    onerror(e, obj)\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 310, in _on_queue_feeder_error\n",
      "    self.thread_wakeup.wakeup()\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 155, in wakeup\n",
      "    self._writer.send_bytes(b\"\")\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/multiprocessing/connection.py\", line 183, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"/home/ehoang/miniconda3/envs/py37/lib/python3.7/multiprocessing/connection.py\", line 136, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_bert_score(sim_thres, bIdx, b, scorer):\n",
    "    time_start = time.time()\n",
    "    count =0\n",
    "    \n",
    "    for i in range(len(b)-1):\n",
    "        refs= [b[x] for x in range(i+1, len(b))]\n",
    "        _, _, f1 = scorer.score([data[b[i]]]*len(refs), list(data[refs]))\n",
    "        f1 = f1.numpy()\n",
    "        count+=np.count_nonzero(f1 >0.1)\n",
    "        for idx, score in enumerate(f1):\n",
    "            if score > sim_thres:\n",
    "                count+=2\n",
    "    print(\"buc: {}-len: {}--{}, {}\".format(bIdx,  len(b), time.time()-time_start, count*2/(len(b)*len(b))))\n",
    "    \n",
    "buckets = lsh_tfidf.extract_nearby_bins(max_search_radius = 0)\n",
    "print(\"#buckets: {}\".format(len(buckets)))\n",
    "\n",
    "Parallel(n_jobs=2)(delayed(compute_bert_score)(0.2, bIdx, b, scorer) for bIdx, b in enumerate(buckets[0:2]))\n",
    "# _ = Parallel(n_jobs=2)(delayed(compute_bert_score)(0.2, bIdx, b, scorer) for bIdx, [b, scorer] in enumerate(zip(buckets[0:2], scorers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 4\n",
      "1 2 5\n",
      "2 3 6\n"
     ]
    }
   ],
   "source": [
    "x =  [1, 2, 3]\n",
    "y = [4, 5, 6]\n",
    "for i, [t, k] in enumerate(zip(x, y)):\n",
    "    print(i, t, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BERTScorer' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-dd8ba180c898>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscorers1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscorers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mscorers1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscorers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'BERTScorer' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "scorers1 = []\n",
    "for i in range(len(scorers)):\n",
    "    scorers1.append(scorers[i].to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorers[0].nthreads= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScorer(hash=roberta-large_L17_no-idf_version=0.3.6(hug_trans=3.3.1)-rescaled, batch_size=64, nthreads=1)\n",
      "BERTScorer(hash=roberta-large_L17_no-idf_version=0.3.6(hug_trans=3.3.1)-rescaled, batch_size=64, nthreads=4)\n"
     ]
    }
   ],
   "source": [
    "for i in scorers:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "# from multiprocressing import Queue\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "# Define number of GPUs available\n",
    "N_GPU = 2\n",
    "\n",
    "# # Put indices in queue\n",
    "# q = queue(maxsize=N_GPU)\n",
    "# for i in range(N_GPU):\n",
    "#     q.put(i)\n",
    "\n",
    "# print(list(q.queue))\n",
    "\n",
    "def runner(i, x):\n",
    "    print(i)\n",
    "    \n",
    "    \n",
    "#     gpu = q.get()\n",
    "#     x._model.to('cuda:'+str(gpu))\n",
    "    \n",
    "    print (x.score([str(data[0])], [str(data[0])]))\n",
    "    print('done')\n",
    "    # Put here your job cmd\n",
    "#     cmd = \"python main.py %s\" % x\n",
    "#     os.system(\"CUDA_VISIBLE_DEVICES=%d %s\" % (gpu, cmd))\n",
    "\n",
    "    # return gpu id to queue\n",
    "#     q.put([gpu, deepcopy(x)])\n",
    "\n",
    "# Change loop\n",
    "Parallel(n_jobs=N_GPU, backend=\"multiprocessing\")(\n",
    "    delayed(runner)(i, scorer) for i, scorer in enumerate(scorers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#buckets: 256\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lex_tfidf = Lexrank(np.array(data['Tweet']), lsh_tfidf)\n",
    "lex_tfidf.build_graph_bert_score(scorers, nJobs = 4, search_radius = 1, sim_thres = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 10\n",
      "Iteration: 20\n",
      "Iteration: 30\n",
      "Iteration: 40\n",
      "Iteration: 50\n",
      "Iteration: 60\n",
      "Iteration: 70\n",
      "Iteration: 80\n",
      "Iteration: 90\n"
     ]
    }
   ],
   "source": [
    "lex_tfidf.train(lexrank_iter = 100, damping_factor = 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting sentences....\n",
      "Sent scores: 10000\n",
      "selected one: 1708, 0.000556831422727555\n",
      "selected one: 1430, 0.0004976549535058439\n",
      "selected one: 373, 0.00047330930829048157\n",
      "selected one: 214, 0.0004665775632020086\n",
      "selected one: 1689, 0.0004551210440695286\n",
      "selected one: 417, 0.000394654693081975\n",
      "selected one: 3080, 0.000389478518627584\n",
      "selected one: 25, 0.0003785667649935931\n",
      "selected one: 1369, 0.000376440875697881\n",
      "selected one: 455, 0.0003686040872707963\n",
      "selected one: 6907, 0.0003566291998140514\n",
      "selected one: 369, 0.0003566105442587286\n",
      "selected one: 3029, 0.0003495930868666619\n",
      "selected one: 80, 0.0003444254689384252\n",
      "selected one: 6395, 0.00034216122003272176\n",
      "selected one: 2730, 0.00034100376069545746\n",
      "selected one: 7144, 0.00033905619056895375\n",
      "selected one: 1471, 0.0003382976574357599\n",
      "selected one: 163, 0.00033712407457642257\n",
      "selected one: 7719, 0.0003328357997816056\n"
     ]
    }
   ],
   "source": [
    "sentIds = lex_tfidf.extract_summary(n_sents = 20, cosine_thres=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id #adjacentEdges lexrank\n",
      "0 1708 12 tensor(0.0006)\n",
      "1 1430 20 tensor(0.0005)\n",
      "2 373 16 tensor(0.0005)\n",
      "3 214 10 tensor(0.0005)\n",
      "4 1689 12 tensor(0.0005)\n",
      "5 417 8 tensor(0.0004)\n",
      "6 3080 8 tensor(0.0004)\n",
      "7 25 11 tensor(0.0004)\n",
      "8 1369 7 tensor(0.0004)\n",
      "9 455 10 tensor(0.0004)\n",
      "10 6907 10 tensor(0.0004)\n",
      "11 369 6 tensor(0.0004)\n",
      "12 3029 6 tensor(0.0003)\n",
      "13 80 5 tensor(0.0003)\n",
      "14 6395 6 tensor(0.0003)\n",
      "15 2730 6 tensor(0.0003)\n",
      "16 7144 4 tensor(0.0003)\n",
      "17 1471 14 tensor(0.0003)\n",
      "18 163 12 tensor(0.0003)\n",
      "19 7719 10 tensor(0.0003)\n"
     ]
    }
   ],
   "source": [
    "print(\"Id\", \"#adjacentEdges\", \"lexrank\")\n",
    "for i, idx in enumerate(sentIds):\n",
    "    print(i, idx, len(lex_tfidf.graph[idx]), lex_tfidf.scores[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 president trump signs executive order targeting refugees\n",
      "1 trump says syrian christian refugees will be given priority for entering u.s. !\n",
      "2 statement from on trump's immigration executive orders\n",
      "3 link : trump's radical immigration plan : enforce the law .\n",
      "4 president trump has signed an executive action implementing \" new vetting measures \" for immigrants …\n",
      "5 breaking : president trump expected to sign executive order restricting immigration from 7 muslim countries !\n",
      "6 the disastrous consequences of trump’s new immigration rules\n",
      "7 trump's immigration ban excludes countries with business ties via\n",
      "8 take action against trump's executive order slamming the door on refugees .\n",
      "9 watch prime minister theresa may’s meeting with president trump\n",
      "10 refugees challenge trump executive order after being detained at u.s. airports\n",
      "11 trump’s proposed refugee ban would abandon iraqis who risked their lives working for the u.s. military …\n",
      "12 #trump trump suspends refugee entry , vows priority for christians\n",
      "13 leaked : read the full draft of trump executive order restricting muslim entry into #usa - #border\n",
      "14 refugees detained at u.s. airports , prompting legal challenges to trump’s immigration order , via\n",
      "15 read the full text of trump's executive order limiting muslim entry to the u.s. …\n",
      "16 #atlhomeinvasion house party tonight ️ everyone free til 11 free drinks| 3810 austin ct atlanta ga 30331 2\n",
      "17 trump says syrian christian refugees will be given priority for entering u.s. !  see her …\n",
      "18 trump's first week : the executive orders donald trump has signed so far and what they mean …\n",
      "19 refugees detained at u.s. airports challenge trump’s executive order\n"
     ]
    }
   ],
   "source": [
    "# with idf\n",
    "for i, idx in enumerate(sentIds):\n",
    "    print(i, data.iloc[idx]['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 president trump signs executive order targeting refugees\n",
      "1 trump says syrian christian refugees will be given priority for entering u.s. !\n",
      "2 statement from on trump's immigration executive orders\n",
      "3 link : trump's radical immigration plan : enforce the law .\n",
      "4 president trump has signed an executive action implementing \" new vetting measures \" for immigrants …\n",
      "5 breaking : president trump expected to sign executive order restricting immigration from 7 muslim countries !\n",
      "6 the disastrous consequences of trump’s new immigration rules\n",
      "7 trump's immigration ban excludes countries with business ties via\n",
      "8 take action against trump's executive order slamming the door on refugees .\n",
      "9 watch prime minister theresa may’s meeting with president trump\n",
      "10 refugees challenge trump executive order after being detained at u.s. airports\n",
      "11 trump’s proposed refugee ban would abandon iraqis who risked their lives working for the u.s. military …\n",
      "12 #trump trump suspends refugee entry , vows priority for christians\n",
      "13 leaked : read the full draft of trump executive order restricting muslim entry into #usa - #border\n",
      "14 refugees detained at u.s. airports , prompting legal challenges to trump’s immigration order , via\n",
      "15 read the full text of trump's executive order limiting muslim entry to the u.s. …\n",
      "16 #atlhomeinvasion house party tonight ️ everyone free til 11 free drinks| 3810 austin ct atlanta ga 30331 2\n",
      "17 trump says syrian christian refugees will be given priority for entering u.s. !  see her …\n",
      "18 trump's first week : the executive orders donald trump has signed so far and what they mean …\n",
      "19 refugees detained at u.s. airports challenge trump’s executive order\n"
     ]
    }
   ],
   "source": [
    "# with idf\n",
    "for i, idx in enumerate(sentIds):\n",
    "    print(i, data.iloc[idx]['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "following trump’s executive order , green card , visa holders already blocked at airports …\n",
    "1 trump executive order : refugees detained at us airports follow for more\n",
    "2 trump signs executive order for ‘ extreme vetting ’ of refugees\n",
    "3 trump executive order : refugees detained at us airports\n",
    "4 trump's state visit to the uk :\n",
    "5 list of trump's executive orders |\n",
    "6 trump executive order : refugees detained at us airports - bbc news\n",
    "7 breaking : prime minister theresa may has arrived at the white house for talks with president trump .\n",
    "8 trump signs executive actions on immigration , military\n",
    "9 president trump signs executive order temporarily halting all refugees\n",
    "10 trump signs ' new vetting ' immigration order\n",
    "11 trump says syrian christian refugees will be given priority for entering u.s. !\n",
    "12 ' we don't want them here ' president trump signs executive order for ' extreme vetting ' of refugees …\n",
    "13 trump’s immigration ban excludes countries with business ties\n",
    "14 breaking : trump to sign executive order today to temporarily halt refugees from some muslim-majority countries - white house\n",
    "15 trump orders ' extreme vetting ' of refugees\n",
    "16 refugees on the way to the u.s. when president trump's executive order was signed were detained at airports …\n",
    "17 trump signs ' extreme vetting ' order to block refugees\n",
    "18 prime minister theresa may arrives at the white house for a meeting with president donald trump\n",
    "19 donald trump has gone too far for dick cheney . dick cheney !!! that dick cheney ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{318: tensor(0.4154),\n",
       " 721: tensor(0.1207),\n",
       " 1072: tensor(0.4366),\n",
       " 2981: tensor(0.2801),\n",
       " 3612: tensor(0.1630),\n",
       " 4336: tensor(0.3717),\n",
       " 4422: tensor(0.1017),\n",
       " 4492: tensor(0.1199),\n",
       " 4604: tensor(0.1046),\n",
       " 6040: tensor(0.4027),\n",
       " 6088: tensor(0.1614),\n",
       " 7588: tensor(0.2022)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex_tfidf.graph[1708]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3083: tensor(0.2183),\n",
       " 4099: tensor(0.2883),\n",
       " 4318: tensor(0.3272),\n",
       " 4593: tensor(0.3452),\n",
       " 4962: tensor(0.1903),\n",
       " 5040: tensor(0.1836),\n",
       " 5144: tensor(0.1750),\n",
       " 6179: tensor(0.2547),\n",
       " 6600: tensor(0.1153),\n",
       " 6698: tensor(0.3994),\n",
       " 6907: tensor(0.2541),\n",
       " 7123: tensor(0.1382),\n",
       " 7353: tensor(0.6009)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex_tfidf.graph[4375] #first tweet of tfidf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "following trump’s executive order , green card , visa holders already blocked at airports …\n",
    "1 trump executive order : refugees detained at us airports follow for more\n",
    "2 trump signs executive order for ‘ extreme vetting ’ of refugees\n",
    "3 trump executive order : refugees detained at us airports\n",
    "4 trump's state visit to the uk :\n",
    "5 list of trump's executive orders |\n",
    "6 trump executive order : refugees detained at us airports - bbc news\n",
    "7 breaking : prime minister theresa may has arrived at the white house for talks with president trump .\n",
    "8 trump signs executive actions on immigration , military\n",
    "9 president trump signs executive order temporarily halting all refugees\n",
    "10 trump signs ' new vetting ' immigration order\n",
    "11 trump says syrian christian refugees will be given priority for entering u.s. !\n",
    "12 ' we don't want them here ' president trump signs executive order for ' extreme vetting ' of refugees …\n",
    "13 trump’s immigration ban excludes countries with business ties\n",
    "14 breaking : trump to sign executive order today to temporarily halt refugees from some muslim-majority countries - white house\n",
    "15 trump orders ' extreme vetting ' of refugees\n",
    "16 refugees on the way to the u.s. when president trump's executive order was signed were detained at airports …\n",
    "17 trump signs ' extreme vetting ' order to block refugees\n",
    "18 prime minister theresa may arrives at the white house for a meeting with president donald trump\n",
    "19 donald trump has gone too far for dick cheney . dick cheney !!! that dick cheney ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 not everyone in the u.k. is overjoyed about may’s meeting with trump\n",
      "1 link : trump's radical immigration plan : enforce the law .\n",
      "2 the real danger is the rippling effect of trump’s ban on syrian refugees , both abroad and in the u.s.\n",
      "3 take action against trump's executive order slamming the door on refugees .\n",
      "4 trump’s proposed refugee ban would abandon iraqis who risked their lives working for the u.s. military …\n",
      "5 president trump signs executive order targeting refugees\n",
      "6 trump says syrian christian refugees will be given priority for entering u.s. !\n",
      "7 read the full text of trump's executive order limiting muslim entry to the u.s. …\n",
      "8 breaking : president trump expected to sign executive order restricting immigration from 7 muslim countries !\n",
      "9 entire senior management of state department quit in apparent gesture of defiance to trump …\n",
      "10 wsj : trump signs executive action that he says would keep “ radical islamic terrorists ” out of the u.s.\n",
      "11 donald trump and theresa may hold joint white house press conference - politics live\n",
      "12 i generally keep my political commentary to a minimum . but trump's refugee ban is un-american .\n",
      "13 president trump has signed an executive action implementing \" new vetting measures \" for immigrants …\n",
      "14 #breakingnews trump signs executive action for \" new vetting measures \" to keep out \" radical islamic terrorists \" …\n",
      "15 the disastrous consequences of trump’s new immigration rules\n",
      "16 leaked : read the full draft of trump executive order restricting muslim entry into #usa - #border\n",
      "17 syrians are heartbroken after hearing trump’s plan to ban refugees from the us via\n",
      "18 warren : trump's refugee ban is a \" betrayal of american values \"\n",
      "19 trump is banning refugees from muslim countries . except those linked to his business\n"
     ]
    }
   ],
   "source": [
    "# without idf\n",
    "for i, idx in enumerate(sentIds):\n",
    "    print(i, data.iloc[idx]['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tweet1</th>\n",
       "      <th>uniWPercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>825064765261176832</td>\n",
       "      <td>company sent out a notice about trump's muslim...</td>\n",
       "      <td>company sent notice trumps muslim ban green ca...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>825137645504172032</td>\n",
       "      <td>visas being denied immediately . chaos at airp...</td>\n",
       "      <td>visas denied immediately chaos airports air mu...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>825141021906382848</td>\n",
       "      <td>ban applies if you have a visa , green card , ...</td>\n",
       "      <td>ban applies visa green card even dual citizen ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>825147334342303745</td>\n",
       "      <td>current concern : what about people with green...</td>\n",
       "      <td>current concern people green cards currently a...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>825152564652081157</td>\n",
       "      <td>many elderly come to green card interview with...</td>\n",
       "      <td>many elderly come green card interview suit ti...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9902</th>\n",
       "      <td>825405997065830402</td>\n",
       "      <td>i want to repeat : green card holders were han...</td>\n",
       "      <td>want repeat green card holders handcuffed soci...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918</th>\n",
       "      <td>825406219376525312</td>\n",
       "      <td>dems , where is your response to what is happe...</td>\n",
       "      <td>dems response happening wrt muslimban refugees...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9922</th>\n",
       "      <td>825406307452801028</td>\n",
       "      <td>green card holders included in trump ban : hom...</td>\n",
       "      <td>green card holders included trump ban homeland...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>825406932395626497</td>\n",
       "      <td>and here .... green card holders , too . may w...</td>\n",
       "      <td>green card holders may whatever god universe b...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>825407305701208064</td>\n",
       "      <td>dear international community : in cities aroun...</td>\n",
       "      <td>dear international community cities around wor...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Id                                              Tweet  \\\n",
       "1216  825064765261176832  company sent out a notice about trump's muslim...   \n",
       "2323  825137645504172032  visas being denied immediately . chaos at airp...   \n",
       "2419  825141021906382848  ban applies if you have a visa , green card , ...   \n",
       "2609  825147334342303745  current concern : what about people with green...   \n",
       "2755  825152564652081157  many elderly come to green card interview with...   \n",
       "...                  ...                                                ...   \n",
       "9902  825405997065830402  i want to repeat : green card holders were han...   \n",
       "9918  825406219376525312  dems , where is your response to what is happe...   \n",
       "9922  825406307452801028  green card holders included in trump ban : hom...   \n",
       "9975  825406932395626497  and here .... green card holders , too . may w...   \n",
       "9996  825407305701208064  dear international community : in cities aroun...   \n",
       "\n",
       "                                                 Tweet1  uniWPercent  \n",
       "1216  company sent notice trumps muslim ban green ca...           10  \n",
       "2323  visas denied immediately chaos airports air mu...           13  \n",
       "2419  ban applies visa green card even dual citizen ...            9  \n",
       "2609  current concern people green cards currently a...           13  \n",
       "2755  many elderly come green card interview suit ti...           12  \n",
       "...                                                 ...          ...  \n",
       "9902  want repeat green card holders handcuffed soci...           12  \n",
       "9918  dems response happening wrt muslimban refugees...           12  \n",
       "9922  green card holders included trump ban homeland...            9  \n",
       "9975  green card holders may whatever god universe b...            9  \n",
       "9996  dear international community cities around wor...           14  \n",
       "\n",
       "[147 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Tweet'].str.contains('green card')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7.3",
   "language": "python",
   "name": "python3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
